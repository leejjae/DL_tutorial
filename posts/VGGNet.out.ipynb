{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VGGNet\n",
        "\n",
        "이정재  \n",
        "2024-01-30\n",
        "\n",
        "## \\## **VGGNet**\n",
        "\n",
        "-   VGGNet 구조 살펴보기\n",
        "\n",
        "<figure class=\"margin-caption\">\n",
        "<img src=\"https://miro.medium.com/max/1100/0*6VP81rFoLWp10FcG.png\"\n",
        "alt=\"VGG\" />\n",
        "<figcaption aria-hidden=\"true\">VGG</figcaption>\n",
        "</figure>\n",
        "\n",
        "## `Step 1` : Load libraries & Datasets"
      ],
      "id": "7c55df1f-e10e-43c8-aeb8-3695797ad141"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")"
      ],
      "id": "d0cf32bb-acbe-491b-a997-c168747576c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 2` : Data preprocessing\n",
        "\n",
        "불러온 이미지의 증강을 통해 학습 정확도를 향상시키도록 합니다.\n",
        "\n",
        "`-` RandomCrop  \n",
        "`-` RandomHorizontalFlip  \n",
        "`-` Normalize"
      ],
      "id": "a12e9c90-0345-4a5b-bd93-3bc7a762ab19"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "train_img = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform,\n",
        ")\n",
        "\n",
        "test_img = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")"
      ],
      "id": "148e1dd3-f4a5-4ff0-a8b6-89e48ccdbcb8"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_img.data.shape"
      ],
      "id": "fa32cbbb-a6cf-4abb-8485-717324c4852b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 3` : Set hyperparameters"
      ],
      "id": "181291f8-24ab-4c05-8e3f-44216e0ea72a"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "batch_sizes = 32\n",
        "learning_rate = 1e-3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using Device:\", device)"
      ],
      "id": "a64ff7a3-2c21-43c1-98a9-5e25bc42d4ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 4` : Create DataLoader"
      ],
      "id": "dbbdaa56-a273-46c5-bdd6-8fcdaac7235c"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_img, batch_size = batch_sizes, shuffle = True)\n",
        "test_loader = DataLoader(test_img, batch_size = batch_sizes, shuffle = False)"
      ],
      "id": "c69bb495-0f17-4fdb-87dd-18ec9f6573fd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 5` : Set Network Structure"
      ],
      "id": "63cad0db-3bee-4359-a938-000209d5f6ed"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}"
      ],
      "id": "3d415be2-83d0-4843-94b4-7a106feb51ed"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 360),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(360, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(100, 10),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),  # 추가\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "                \n",
        "        return nn.Sequential(*layers)"
      ],
      "id": "cd133d8c-0abe-4e33-9414-b988dceeb781"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 6` : Create Model instance"
      ],
      "id": "ac9971f4-070f-44c5-965b-531c0eaa4b31"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=360, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=360, out_features=100, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")"
          ]
        }
      ],
      "source": [
        "model = VGG('VGG16').to(device)\n",
        "print(model)"
      ],
      "id": "e7f2b6be-e8a2-402f-a49e-d14b3363c029"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 7` : Model compile"
      ],
      "id": "6b18072d-8ba1-43cd-93cd-e4a40ad7fa05"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ],
      "id": "e49cfe4c-44e5-4e73-a246-dd676baf0eed"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 8` : Set train loop"
      ],
      "id": "e91322a9-423d-449c-8f35-b552751ce2e8"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_loader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    size = len(train_loader.dataset)\n",
        "\n",
        "    for batch, (X,y) in enumerate(train_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "\n",
        "        # loss calculation\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f'loss: {loss:>7f}   [{current:>5d}]/{size:5d}')"
      ],
      "id": "a76cacfe-e7d2-4afd-9892-111a3d73bbf4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 9` : Set test loop"
      ],
      "id": "31f58e4e-6436-437b-b986-8d8510e41e30"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(test_loader, model, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    size = len(test_loader.dataset)\n",
        "    num_batches = len(test_loader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y  = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n\")"
      ],
      "id": "f8c183b6-efdc-4ae7-b959-4440ea670507"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `Step 10` : Run model"
      ],
      "id": "d38bd6f3-5d71-4dce-9be6-c229dcc00c18"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "---------------------------\n",
            "loss: 2.336054   [    0]/50000\n",
            "loss: 2.201652   [ 3200]/50000\n",
            "loss: 1.913308   [ 6400]/50000\n",
            "loss: 1.833156   [ 9600]/50000\n",
            "loss: 2.025965   [12800]/50000\n",
            "loss: 1.458568   [16000]/50000\n",
            "loss: 1.454589   [19200]/50000\n",
            "loss: 1.586300   [22400]/50000\n",
            "loss: 1.777550   [25600]/50000\n",
            "loss: 1.902973   [28800]/50000\n",
            "loss: 1.534656   [32000]/50000\n",
            "loss: 1.808721   [35200]/50000\n",
            "loss: 1.449842   [38400]/50000\n",
            "loss: 1.357022   [41600]/50000\n",
            "loss: 1.378457   [44800]/50000\n",
            "loss: 1.557457   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 50.6%, Avg loss: 1.338251\n",
            "\n",
            "Epoch 2 \n",
            "---------------------------\n",
            "loss: 1.564054   [    0]/50000\n",
            "loss: 1.571676   [ 3200]/50000\n",
            "loss: 1.477239   [ 6400]/50000\n",
            "loss: 1.520172   [ 9600]/50000\n",
            "loss: 1.256163   [12800]/50000\n",
            "loss: 1.066607   [16000]/50000\n",
            "loss: 1.460073   [19200]/50000\n",
            "loss: 1.077838   [22400]/50000\n",
            "loss: 1.215548   [25600]/50000\n",
            "loss: 0.884830   [28800]/50000\n",
            "loss: 1.028723   [32000]/50000\n",
            "loss: 1.288996   [35200]/50000\n",
            "loss: 1.299563   [38400]/50000\n",
            "loss: 0.939404   [41600]/50000\n",
            "loss: 0.955451   [44800]/50000\n",
            "loss: 1.098657   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 67.3%, Avg loss: 0.923354\n",
            "\n",
            "Epoch 3 \n",
            "---------------------------\n",
            "loss: 0.796024   [    0]/50000\n",
            "loss: 0.677388   [ 3200]/50000\n",
            "loss: 0.617442   [ 6400]/50000\n",
            "loss: 1.173936   [ 9600]/50000\n",
            "loss: 0.786573   [12800]/50000\n",
            "loss: 0.798586   [16000]/50000\n",
            "loss: 1.181702   [19200]/50000\n",
            "loss: 0.897227   [22400]/50000\n",
            "loss: 0.735924   [25600]/50000\n",
            "loss: 1.028793   [28800]/50000\n",
            "loss: 0.834691   [32000]/50000\n",
            "loss: 1.081767   [35200]/50000\n",
            "loss: 0.828031   [38400]/50000\n",
            "loss: 1.046338   [41600]/50000\n",
            "loss: 0.828228   [44800]/50000\n",
            "loss: 1.146716   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 70.4%, Avg loss: 0.880181\n",
            "\n",
            "Epoch 4 \n",
            "---------------------------\n",
            "loss: 0.617879   [    0]/50000\n",
            "loss: 0.876245   [ 3200]/50000\n",
            "loss: 0.673582   [ 6400]/50000\n",
            "loss: 0.556679   [ 9600]/50000\n",
            "loss: 0.699025   [12800]/50000\n",
            "loss: 1.006697   [16000]/50000\n",
            "loss: 0.683750   [19200]/50000\n",
            "loss: 1.277821   [22400]/50000\n",
            "loss: 0.562071   [25600]/50000\n",
            "loss: 0.686587   [28800]/50000\n",
            "loss: 0.873322   [32000]/50000\n",
            "loss: 0.719097   [35200]/50000\n",
            "loss: 0.457578   [38400]/50000\n",
            "loss: 0.514047   [41600]/50000\n",
            "loss: 0.729195   [44800]/50000\n",
            "loss: 0.858265   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 75.3%, Avg loss: 0.712957\n",
            "\n",
            "Epoch 5 \n",
            "---------------------------\n",
            "loss: 0.855375   [    0]/50000\n",
            "loss: 0.854320   [ 3200]/50000\n",
            "loss: 0.695397   [ 6400]/50000\n",
            "loss: 0.525759   [ 9600]/50000\n",
            "loss: 0.381186   [12800]/50000\n",
            "loss: 0.587416   [16000]/50000\n",
            "loss: 0.511339   [19200]/50000\n",
            "loss: 1.319725   [22400]/50000\n",
            "loss: 0.649993   [25600]/50000\n",
            "loss: 0.508207   [28800]/50000\n",
            "loss: 0.585140   [32000]/50000\n",
            "loss: 0.794928   [35200]/50000\n",
            "loss: 0.799448   [38400]/50000\n",
            "loss: 0.417046   [41600]/50000\n",
            "loss: 0.498251   [44800]/50000\n",
            "loss: 0.779942   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 76.6%, Avg loss: 0.682496\n",
            "\n",
            "Epoch 6 \n",
            "---------------------------\n",
            "loss: 0.719160   [    0]/50000\n",
            "loss: 0.627115   [ 3200]/50000\n",
            "loss: 0.255042   [ 6400]/50000\n",
            "loss: 0.400026   [ 9600]/50000\n",
            "loss: 0.737379   [12800]/50000\n",
            "loss: 0.741243   [16000]/50000\n",
            "loss: 0.726986   [19200]/50000\n",
            "loss: 0.266388   [22400]/50000\n",
            "loss: 0.633677   [25600]/50000\n",
            "loss: 0.482972   [28800]/50000\n",
            "loss: 0.444857   [32000]/50000\n",
            "loss: 0.513320   [35200]/50000\n",
            "loss: 0.529961   [38400]/50000\n",
            "loss: 0.784853   [41600]/50000\n",
            "loss: 0.560646   [44800]/50000\n",
            "loss: 0.426722   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 75.4%, Avg loss: 0.737327\n",
            "\n",
            "Epoch 7 \n",
            "---------------------------\n",
            "loss: 0.456941   [    0]/50000\n",
            "loss: 0.552954   [ 3200]/50000\n",
            "loss: 0.588921   [ 6400]/50000\n",
            "loss: 0.359172   [ 9600]/50000\n",
            "loss: 0.380740   [12800]/50000\n",
            "loss: 0.230270   [16000]/50000\n",
            "loss: 0.544868   [19200]/50000\n",
            "loss: 0.470449   [22400]/50000\n",
            "loss: 0.716484   [25600]/50000\n",
            "loss: 0.427520   [28800]/50000\n",
            "loss: 0.485696   [32000]/50000\n",
            "loss: 0.250514   [35200]/50000\n",
            "loss: 0.619605   [38400]/50000\n",
            "loss: 0.534625   [41600]/50000\n",
            "loss: 0.294415   [44800]/50000\n",
            "loss: 0.676517   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.560385\n",
            "\n",
            "Epoch 8 \n",
            "---------------------------\n",
            "loss: 0.584514   [    0]/50000\n",
            "loss: 0.433411   [ 3200]/50000\n",
            "loss: 0.360651   [ 6400]/50000\n",
            "loss: 0.707992   [ 9600]/50000\n",
            "loss: 0.449344   [12800]/50000\n",
            "loss: 0.380623   [16000]/50000\n",
            "loss: 0.333079   [19200]/50000\n",
            "loss: 0.420316   [22400]/50000\n",
            "loss: 0.414326   [25600]/50000\n",
            "loss: 0.539709   [28800]/50000\n",
            "loss: 0.425368   [32000]/50000\n",
            "loss: 0.610167   [35200]/50000\n",
            "loss: 0.427243   [38400]/50000\n",
            "loss: 0.787724   [41600]/50000\n",
            "loss: 0.561038   [44800]/50000\n",
            "loss: 0.456995   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.566010\n",
            "\n",
            "Epoch 9 \n",
            "---------------------------\n",
            "loss: 0.383341   [    0]/50000\n",
            "loss: 0.381802   [ 3200]/50000\n",
            "loss: 0.258570   [ 6400]/50000\n",
            "loss: 0.421782   [ 9600]/50000\n",
            "loss: 0.455991   [12800]/50000\n",
            "loss: 0.531303   [16000]/50000\n",
            "loss: 0.758386   [19200]/50000\n",
            "loss: 0.285010   [22400]/50000\n",
            "loss: 0.314713   [25600]/50000\n",
            "loss: 0.419822   [28800]/50000\n",
            "loss: 0.278820   [32000]/50000\n",
            "loss: 0.553399   [35200]/50000\n",
            "loss: 0.416081   [38400]/50000\n",
            "loss: 0.365547   [41600]/50000\n",
            "loss: 0.686296   [44800]/50000\n",
            "loss: 0.814931   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.502169\n",
            "\n",
            "Epoch 10 \n",
            "---------------------------\n",
            "loss: 0.275047   [    0]/50000\n",
            "loss: 0.573386   [ 3200]/50000\n",
            "loss: 0.737843   [ 6400]/50000\n",
            "loss: 0.478916   [ 9600]/50000\n",
            "loss: 0.429536   [12800]/50000\n",
            "loss: 0.238580   [16000]/50000\n",
            "loss: 0.406505   [19200]/50000\n",
            "loss: 0.228436   [22400]/50000\n",
            "loss: 0.370529   [25600]/50000\n",
            "loss: 0.344406   [28800]/50000\n",
            "loss: 0.301163   [32000]/50000\n",
            "loss: 0.257651   [35200]/50000\n",
            "loss: 0.833092   [38400]/50000\n",
            "loss: 0.897587   [41600]/50000\n",
            "loss: 0.397286   [44800]/50000\n",
            "loss: 0.637342   [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.467348\n",
            "\n",
            "Done!"
          ]
        }
      ],
      "source": [
        "for i in range(epochs):\n",
        "    print(f\"Epoch {i+1} \\n---------------------------\")\n",
        "    train(train_loader, model, loss, optimizer)\n",
        "    test(test_loader, model, loss)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "a8689ee8-d1cb-4053-94c3-8591ea122ad4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \\## CIFAR Classifier(Pretrained VGGNet)\n",
        "\n",
        "ImageNet 데이터로 학습한 VGGNet을 사용하여 주어진 데이터 셋에서 사용할\n",
        "수 있도록 Fine tuning 해봅니다."
      ],
      "id": "02ef51f0-5bf1-4870-911c-cb135c33e7fd"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  }
}